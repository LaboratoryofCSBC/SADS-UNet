{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "numerous-attendance",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "promising-biotechnology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T16:22:04.041636Z",
     "start_time": "2024-03-09T16:22:03.990357Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"#使用第一块GPU（从0开始）\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "\n",
    "from help_functions import *\n",
    "from pre_processing import my_PreProc\n",
    "from extract_patches import get_data_training, recompone, recompone_overlap, paint_border, kill_border, pred_only_FOV, get_data_testing, paint_border_overlap, extract_ordered_overlap, get_data_testing_overlap, get_DRHAGIS_testing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Multiply,Add, Concatenate\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, concatenate, UpSampling2D, Conv2DTranspose, AveragePooling2D, SeparableConv2D\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "from tensorflow.python.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import  ModelCheckpoint,LearningRateScheduler,EarlyStopping,Callback\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as KL\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-forty",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "steady-monroe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T14:22:40.561087Z",
     "start_time": "2024-03-11T14:22:40.421314Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 11 22:22:40 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.24.02    Driver Version: 465.24.02    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |\r\n",
      "| 34%   43C    P8    26W / 260W |      3MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:68:00.0  On |                  N/A |\r\n",
      "| 57%   60C    P8    41W / 260W |  10894MiB / 11016MiB |      6%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A      1230      G   /usr/lib/xorg/Xorg                 51MiB |\r\n",
      "|    1   N/A  N/A     16421      C   ...conda3/envs/py/bin/python    10839MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "egyptian-coral",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:22:45.572830Z",
     "start_time": "2024-03-09T13:22:45.566218Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataset path\n",
    "dataset_path_test = \"./DRHAGIS/test/\"\n",
    "dataset_path_train = \"./DRHAGIS/train/\"\n",
    "#train dataset path\n",
    "original_imgs_train_1 = dataset_path_train + \"DRHAGIS_dataset_imgs_train_1.hdf5\"\n",
    "groundTruth_imgs_train_1 = dataset_path_train + \"DRHAGIS_dataset_groundTruth_train_1.hdf5\"\n",
    "borderMasks_imgs_train_1 = dataset_path_train + \"DRHAGIS_dataset_borderMasks_train_1.hdf5\"\n",
    "\n",
    "original_imgs_train_2 = dataset_path_train + \"DRHAGIS_dataset_imgs_train_2.hdf5\"\n",
    "groundTruth_imgs_train_2 = dataset_path_train + \"DRHAGIS_dataset_groundTruth_train_2.hdf5\"\n",
    "borderMasks_imgs_train_2 = dataset_path_train + \"DRHAGIS_dataset_borderMasks_train_2.hdf5\"\n",
    "\n",
    "original_imgs_train_3 = dataset_path_train + \"DRHAGIS_dataset_imgs_train_3.hdf5\"\n",
    "groundTruth_imgs_train_3 = dataset_path_train + \"DRHAGIS_dataset_groundTruth_train_3.hdf5\"\n",
    "borderMasks_imgs_train_3 = dataset_path_train + \"DRHAGIS_dataset_borderMasks_train_3.hdf5\"\n",
    "\n",
    "original_imgs_train_4 = dataset_path_train + \"DRHAGIS_dataset_imgs_train_4.hdf5\"\n",
    "groundTruth_imgs_train_4 = dataset_path_train + \"DRHAGIS_dataset_groundTruth_train_4.hdf5\"\n",
    "borderMasks_imgs_train_4 = dataset_path_train + \"DRHAGIS_dataset_borderMasks_train_4.hdf5\"\n",
    "\n",
    "original_imgs_train_5 = dataset_path_train + \"DRHAGIS_dataset_imgs_train_5.hdf5\"\n",
    "groundTruth_imgs_train_5 = dataset_path_train + \"DRHAGIS_dataset_groundTruth_train_5.hdf5\"\n",
    "borderMasks_imgs_train_5 = dataset_path_train + \"DRHAGIS_dataset_borderMasks_train_5.hdf5\"\n",
    "\n",
    "#test dataset path\n",
    "original_imgs_test_1 = dataset_path_test + \"DRHAGIS_dataset_imgs_test_1.hdf5\"\n",
    "groundTruth_imgs_test_1 = dataset_path_test + \"DRHAGIS_dataset_groundTruth_test_1.hdf5\"\n",
    "borderMasks_imgs_test_1 = dataset_path_test + \"DRHAGIS_dataset_borderMasks_test_1.hdf5\"\n",
    "\n",
    "original_imgs_test_3 = dataset_path_test + \"DRHAGIS_dataset_imgs_test_3.hdf5\"\n",
    "groundTruth_imgs_test_3 = dataset_path_test + \"DRHAGIS_dataset_groundTruth_test_3.hdf5\"\n",
    "borderMasks_imgs_test_3 = dataset_path_test + \"DRHAGIS_dataset_borderMasks_test_3.hdf5\"\n",
    "\n",
    "original_imgs_test_4 = dataset_path_test + \"DRHAGIS_dataset_imgs_test_4.hdf5\"\n",
    "groundTruth_imgs_test_4 = dataset_path_test + \"DRHAGIS_dataset_groundTruth_test_4.hdf5\"\n",
    "borderMasks_imgs_test_4 = dataset_path_test + \"DRHAGIS_dataset_borderMasks_test_4.hdf5\"\n",
    "\n",
    "original_imgs_test_5 = dataset_path_test + \"DRHAGIS_dataset_imgs_test_5.hdf5\"\n",
    "groundTruth_imgs_test_5 = dataset_path_test + \"DRHAGIS_dataset_groundTruth_test_5.hdf5\"\n",
    "borderMasks_imgs_test_5 = dataset_path_test + \"DRHAGIS_dataset_borderMasks_test_5.hdf5\"\n",
    "\n",
    "\n",
    "patch_height, patch_width = 64, 64\n",
    "stride_height, stride_width = 16,16\n",
    "tr_nums_1 = 38025\n",
    "tr_nums_2 = 19881\n",
    "tr_nums_3 = 16900\n",
    "tr_nums_4 = 13924\n",
    "tr_nums_5 = 12996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "educational-ideal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:24:11.285942Z",
     "start_time": "2024-03-09T13:22:51.949593Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train images/masks shape:\n",
      "(9, 1, 3168, 3168)\n",
      "train images range (min-max): 0.01568627450980392 - 0.984313725490196\n",
      "train masks are within 0-1\n",
      "\n",
      "patches per full image: 4225\n",
      "\n",
      "train PATCHES images/masks shape:\n",
      "(38025, 1, 64, 64)\n",
      "train PATCHES images range (min-max): 0.01568627450980392 - 0.984313725490196\n",
      "(38025, 64, 64, 1) (38025, 64, 64, 1) 1.0\n",
      "\n",
      "train images/masks shape:\n",
      "(1, 1, 2304, 2304)\n",
      "train images range (min-max): 0.01568627450980392 - 0.8352941176470589\n",
      "train masks are within 0-1\n",
      "\n",
      "patches per full image: 19881\n",
      "\n",
      "train PATCHES images/masks shape:\n",
      "(19881, 1, 64, 64)\n",
      "train PATCHES images range (min-max): 0.01568627450980392 - 0.8352941176470589\n",
      "(19881, 64, 64, 1) (19881, 64, 64, 1) 1.0\n",
      "\n",
      "train images/masks shape:\n",
      "(10, 1, 2136, 2136)\n",
      "train images range (min-max): 0.01568627450980392 - 0.8980392156862745\n",
      "train masks are within 0-1\n",
      "\n",
      "patches per full image: 1690\n",
      "\n",
      "train PATCHES images/masks shape:\n",
      "(16900, 1, 64, 64)\n",
      "train PATCHES images range (min-max): 0.01568627450980392 - 0.8941176470588236\n",
      "(16900, 64, 64, 1) (16900, 64, 64, 1) 1.0\n",
      "\n",
      "train images/masks shape:\n",
      "(4, 1, 1944, 1944)\n",
      "train images range (min-max): 0.00784313725490196 - 1.0\n",
      "train masks are within 0-1\n",
      "\n",
      "patches per full image: 3481\n",
      "\n",
      "train PATCHES images/masks shape:\n",
      "(13924, 1, 64, 64)\n",
      "train PATCHES images range (min-max): 0.00784313725490196 - 1.0\n",
      "(13924, 64, 64, 1) (13924, 64, 64, 1) 1.0\n",
      "\n",
      "train images/masks shape:\n",
      "(8, 1, 1880, 1880)\n",
      "train images range (min-max): 0.01568627450980392 - 0.9450980392156862\n",
      "train masks are within 0-1\n",
      "\n",
      "N_patches: plase enter a multiple of 20\n",
      "patches per full image: 1624\n",
      "\n",
      "train PATCHES images/masks shape:\n",
      "(12996, 1, 64, 64)\n",
      "train PATCHES images range (min-max): 0.0 - 0.9450980392156862\n",
      "(12996, 64, 64, 1) (12996, 64, 64, 1) 1.0\n",
      "(101726, 64, 64, 1) (101726, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "#load the training data and divided in patches\n",
    "patches_imgs_train_1, patches_masks_train_1 = get_data_training(\n",
    "    train_imgs_original=original_imgs_train_1,\n",
    "    train_groudTruth=groundTruth_imgs_train_1,\n",
    "    patch_height=patch_height,\n",
    "    patch_width=patch_width,\n",
    "    N_subimgs=tr_nums_1,\n",
    "    inside_FOV = False,\n",
    "    dataset_type='DRHAGIS_1'\n",
    ")\n",
    "\n",
    "patches_imgs_train_1 = np.transpose(patches_imgs_train_1, (0, 2, 3, 1))\n",
    "patches_masks_train_1 = np.transpose(patches_masks_train_1, (0, 2, 3, 1))\n",
    "print(patches_masks_train_1.shape, patches_imgs_train_1.shape, np.max(patches_masks_train_1))\n",
    "#tr_data, tr_mask = patches_imgs_train.astype(np.float32), patches_masks_train.astype(np.float32)\n",
    "tr_data_1, tr_mask_1 = patches_imgs_train_1.astype(np.float32), np.round(patches_masks_train_1).astype(np.float32)\n",
    "\n",
    "patches_imgs_train_2, patches_masks_train_2 = get_data_training(\n",
    "    train_imgs_original=original_imgs_train_2,\n",
    "    train_groudTruth=groundTruth_imgs_train_2,\n",
    "    patch_height=patch_height,\n",
    "    patch_width=patch_width,\n",
    "    N_subimgs=tr_nums_2,\n",
    "    inside_FOV = False,\n",
    "    dataset_type='DRHAGIS_2'\n",
    ")\n",
    "\n",
    "patches_imgs_train_2 = np.transpose(patches_imgs_train_2, (0, 2, 3, 1))\n",
    "patches_masks_train_2 = np.transpose(patches_masks_train_2, (0, 2, 3, 1))\n",
    "print(patches_masks_train_2.shape, patches_imgs_train_2.shape, np.max(patches_masks_train_2))\n",
    "#tr_data, tr_mask = patches_imgs_train.astype(np.float32), patches_masks_train.astype(np.float32)\n",
    "tr_data_2, tr_mask_2 = patches_imgs_train_2.astype(np.float32), np.round(patches_masks_train_2).astype(np.float32)\n",
    "\n",
    "patches_imgs_train_3, patches_masks_train_3 = get_data_training(\n",
    "    train_imgs_original=original_imgs_train_3,\n",
    "    train_groudTruth=groundTruth_imgs_train_3,\n",
    "    patch_height=patch_height,\n",
    "    patch_width=patch_width,\n",
    "    N_subimgs=tr_nums_3,\n",
    "    inside_FOV = False,\n",
    "    dataset_type='DRHAGIS_3'\n",
    ")\n",
    "\n",
    "patches_imgs_train_3 = np.transpose(patches_imgs_train_3, (0, 2, 3, 1))\n",
    "patches_masks_train_3 = np.transpose(patches_masks_train_3, (0, 2, 3, 1))\n",
    "print(patches_masks_train_3.shape, patches_imgs_train_3.shape, np.max(patches_masks_train_3))\n",
    "#tr_data, tr_mask = patches_imgs_train.astype(np.float32), patches_masks_train.astype(np.float32)\n",
    "tr_data_3, tr_mask_3 = patches_imgs_train_3.astype(np.float32), np.round(patches_masks_train_3).astype(np.float32)\n",
    "\n",
    "patches_imgs_train_4, patches_masks_train_4 = get_data_training(\n",
    "    train_imgs_original=original_imgs_train_4,\n",
    "    train_groudTruth=groundTruth_imgs_train_4,\n",
    "    patch_height=patch_height,\n",
    "    patch_width=patch_width,\n",
    "    N_subimgs=tr_nums_4,\n",
    "    inside_FOV = False,\n",
    "    dataset_type='DRHAGIS_4'\n",
    ")\n",
    "\n",
    "patches_imgs_train_4 = np.transpose(patches_imgs_train_4, (0, 2, 3, 1))\n",
    "patches_masks_train_4 = np.transpose(patches_masks_train_4, (0, 2, 3, 1))\n",
    "print(patches_masks_train_4.shape, patches_imgs_train_4.shape, np.max(patches_masks_train_4))\n",
    "#tr_data, tr_mask = patches_imgs_train.astype(np.float32), patches_masks_train.astype(np.float32)\n",
    "tr_data_4, tr_mask_4 = patches_imgs_train_4.astype(np.float32), np.round(patches_masks_train_4).astype(np.float32)\n",
    "\n",
    "patches_imgs_train_5, patches_masks_train_5 = get_data_training(\n",
    "    train_imgs_original=original_imgs_train_5,\n",
    "    train_groudTruth=groundTruth_imgs_train_5,\n",
    "    patch_height=patch_height,\n",
    "    patch_width=patch_width,\n",
    "    N_subimgs=tr_nums_5,\n",
    "    inside_FOV = False,\n",
    "    dataset_type='DRHAGIS_5'\n",
    ")\n",
    "\n",
    "patches_imgs_train_5 = np.transpose(patches_imgs_train_5, (0, 2, 3, 1))\n",
    "patches_masks_train_5 = np.transpose(patches_masks_train_5, (0, 2, 3, 1))\n",
    "print(patches_masks_train_5.shape, patches_imgs_train_5.shape, np.max(patches_masks_train_5))\n",
    "#tr_data, tr_mask = patches_imgs_train.astype(np.float32), patches_masks_train.astype(np.float32)\n",
    "tr_data_5, tr_mask_5 = patches_imgs_train_5.astype(np.float32), np.round(patches_masks_train_5).astype(np.float32)\n",
    "\n",
    "tr_data = np.concatenate((tr_data_1, tr_data_2, tr_data_3, tr_data_4, tr_data_5),axis=0)\n",
    "tr_mask = np.concatenate((tr_mask_1, tr_mask_2, tr_mask_3, tr_mask_4, tr_mask_5),axis=0)\n",
    "\n",
    "print(tr_data.shape, tr_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "toxic-chester",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:27:23.978841Z",
     "start_time": "2024-03-09T13:25:12.306617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new full images shape: \n",
      "(2, 1, 3168, 4752)\n",
      "\n",
      "the side H is not compatible with the selected stride of 16\n",
      "img_h 2136, patch_h 64, stride_h 16\n",
      "(img_h - patch_h) MOD stride_h: 8\n",
      "So the H dim will be padded with additional 8 pixels\n",
      "new full images shape: \n",
      "(3, 1, 2144, 3216)\n",
      "\n",
      "the side H is not compatible with the selected stride of 16\n",
      "img_h 1944, patch_h 64, stride_h 16\n",
      "(img_h - patch_h) MOD stride_h: 8\n",
      "So the H dim will be padded with additional 8 pixels\n",
      "new full images shape: \n",
      "(1, 1, 1952, 2896)\n",
      "\n",
      "the side H is not compatible with the selected stride of 16\n",
      "img_h 1880, patch_h 64, stride_h 16\n",
      "(img_h - patch_h) MOD stride_h: 8\n",
      "So the H dim will be padded with additional 8 pixels\n",
      "new full images shape: \n",
      "(2, 1, 1888, 2816)\n",
      "new full images shape: \n",
      "(2, 1, 3168, 4752)\n",
      "\n",
      "the side H is not compatible with the selected stride of 16\n",
      "img_h 2136, patch_h 64, stride_h 16\n",
      "(img_h - patch_h) MOD stride_h: 8\n",
      "So the H dim will be padded with additional 8 pixels\n",
      "new full images shape: \n",
      "(2, 1, 2144, 3216)\n",
      "\n",
      "the side H is not compatible with the selected stride of 16\n",
      "img_h 1944, patch_h 64, stride_h 16\n",
      "(img_h - patch_h) MOD stride_h: 8\n",
      "So the H dim will be padded with additional 8 pixels\n",
      "new full images shape: \n",
      "(1, 1, 1952, 2896)\n",
      "\n",
      "the side H is not compatible with the selected stride of 16\n",
      "img_h 1880, patch_h 64, stride_h 16\n",
      "(img_h - patch_h) MOD stride_h: 8\n",
      "So the H dim will be padded with additional 8 pixels\n",
      "new full images shape: \n",
      "(2, 1, 1888, 2816)\n",
      "\n",
      "test images shape:\n",
      "(2, 1, 3168, 4752) (2, 1, 3168, 4752)\n",
      "(3, 1, 2144, 3216) (2, 1, 2144, 3216)\n",
      "(1, 1, 1952, 2896) (1, 1, 1952, 2896)\n",
      "(2, 1, 1888, 2816) (2, 1, 1888, 2816)\n",
      "test images range (min-max): 0.01568627450980392 - 1.0\n",
      "test images range (min-max): 0.0 - 1.0\n",
      "test images range (min-max): 0.0 - 1.0\n",
      "test images range (min-max): 0.0 - 1.0\n",
      "test masks are within 0-1\n",
      "\n",
      "Number of patches on h : 195\n",
      "Number of patches on w : 294\n",
      "number of patches per image: 57330, totally for this dataset: 114660\n",
      "Number of patches on h : 131\n",
      "Number of patches on w : 198\n",
      "number of patches per image: 25938, totally for this dataset: 77814\n",
      "Number of patches on h : 119\n",
      "Number of patches on w : 178\n",
      "number of patches per image: 21182, totally for this dataset: 21182\n",
      "Number of patches on h : 115\n",
      "Number of patches on w : 173\n",
      "number of patches per image: 19895, totally for this dataset: 39790\n",
      "Number of patches on h : 195\n",
      "Number of patches on w : 294\n",
      "number of patches per image: 57330, totally for this dataset: 114660\n",
      "Number of patches on h : 131\n",
      "Number of patches on w : 198\n",
      "number of patches per image: 25938, totally for this dataset: 51876\n",
      "Number of patches on h : 119\n",
      "Number of patches on w : 178\n",
      "number of patches per image: 21182, totally for this dataset: 21182\n",
      "Number of patches on h : 115\n",
      "Number of patches on w : 173\n",
      "number of patches per image: 19895, totally for this dataset: 39790\n",
      "\n",
      "test PATCHES images shape:\n",
      "(253446, 1, 64, 64)\n",
      "test PATCHES images range (min-max): 0.0 - 1.0\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "#load the testing data and divide in patches\n",
    "patches_imgs_test, new_height, new_width, patches_masks_test = get_DRHAGIS_testing(\n",
    "    test_imgs_original_1 = original_imgs_test_1,\n",
    "    test_imgs_original_2 = original_imgs_test_3,\n",
    "    test_imgs_original_3 = original_imgs_test_4,\n",
    "    test_imgs_original_4 = original_imgs_test_5,\n",
    "    test_groudTruth_1 = groundTruth_imgs_test_1,\n",
    "    test_groudTruth_2 = groundTruth_imgs_test_3,\n",
    "    test_groudTruth_3 = groundTruth_imgs_test_4,\n",
    "    test_groudTruth_4 = groundTruth_imgs_test_5,\n",
    "    Imgs_to_test = [2,3,1,2],\n",
    "    patch_height = patch_height, \n",
    "    patch_width = patch_width, \n",
    "    stride_height = stride_height, \n",
    "    stride_width = stride_width\n",
    ")\n",
    "\n",
    "patches_imgs_test = np.transpose(patches_imgs_test,(0, 2, 3, 1))\n",
    "#te_data,te_mask = patches_imgs_test.astype(np.float32), masks_test.astype(np.float32)\n",
    "te_data = patches_imgs_test.astype(np.float32)\n",
    "te_mask = patches_masks_test.astype(np.float32)\n",
    "\n",
    "#print(tr_data.shape,tr_mask.shape,te_data.shape,te_mask.shape)\n",
    "\n",
    "#save training and testing data\n",
    "np.save('./dataset/tr_data_patch.npy', tr_data)\n",
    "np.save('./dataset/tr_mask_patch.npy', tr_mask)\n",
    "np.save('./dataset/te_data_patch.npy', te_data)\n",
    "np.save('./dataset/te_mask_patch.npy', te_mask)\n",
    "print('saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-quarter",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "residential-bermuda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:34:06.670681Z",
     "start_time": "2024-03-09T13:34:06.653140Z"
    }
   },
   "outputs": [],
   "source": [
    "def FL(y_true,y_pred):\n",
    "    return focal_loss(y_true,y_pred)\n",
    "\n",
    "def focal_loss(y, pred, alpha=0.8, gamma=2.):\n",
    "        r\"\"\"Compute focal loss for predictions.\n",
    "            Multi-labels Focal loss formula:\n",
    "                FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                     ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "        Args:\n",
    "         pred: A float tensor of shape [batch_size, num_anchors,\n",
    "            num_classes] representing the predicted logits for each class\n",
    "         y: A float tensor of shape [batch_size, num_anchors,\n",
    "            num_classes] representing one-hot encoded classification targets\n",
    "         alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "         gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "        Returns:\n",
    "            loss: A (scalar) tensor representing the value of the loss function\n",
    "        \"\"\"\n",
    "        zeros = tf.zeros_like(pred, dtype=pred.dtype)\n",
    "\n",
    "        # For positive prediction, only need consider front part loss, back part is 0;\n",
    "        # target_tensor > zeros <=> z=1, so positive coefficient = z - p.\n",
    "        pos_p_sub = tf.where(y > zeros, y - pred, zeros) # positive sample 寻找正样本，并进行填充\n",
    "\n",
    "        # For negative prediction, only need consider back part loss, front part is 0;\n",
    "        # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "        neg_p_sub = tf.where(y > zeros, zeros, pred) # negative sample 寻找负样本，并进行填充\n",
    "        per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.math.log(tf.clip_by_value(pred, 1e-8, 1.0)) \\\n",
    "                              - (1 - alpha) * (neg_p_sub ** gamma) * tf.math.log(tf.clip_by_value(1.0 - pred, 1e-8, 1.0))\n",
    "\n",
    "        return tf.reduce_mean(per_entry_cross_ent)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1. # 用于防止分母为0.\n",
    "    y_true_f = K.flatten(y_true) # 将 y_true 拉伸为一维.\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f) + smooth)\n",
    "\n",
    "def df_loss(y_true, y_pred):\n",
    "    return 1*dice_loss(y_true, y_pred) + 0.8 * focal_loss(y_true, y_pred)\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   # strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-twelve",
   "metadata": {},
   "source": [
    "# Evaluating and showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "northern-october",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T16:13:12.227769Z",
     "start_time": "2024-03-09T16:13:11.568416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new full images shape: \n",
      "(2, 1, 3168, 4752)\n",
      "\n",
      "the side H is not compatible with the selected stride of 16\n",
      "img_h 2136, patch_h 64, stride_h 16\n",
      "(img_h - patch_h) MOD stride_h: 8\n",
      "So the H dim will be padded with additional 8 pixels\n",
      "new full images shape: \n",
      "(3, 1, 2144, 3216)\n",
      "\n",
      "the side H is not compatible with the selected stride of 16\n",
      "img_h 1944, patch_h 64, stride_h 16\n",
      "(img_h - patch_h) MOD stride_h: 8\n",
      "So the H dim will be padded with additional 8 pixels\n",
      "new full images shape: \n",
      "(1, 1, 1952, 2896)\n",
      "\n",
      "the side H is not compatible with the selected stride of 16\n",
      "img_h 1880, patch_h 64, stride_h 16\n",
      "(img_h - patch_h) MOD stride_h: 8\n",
      "So the H dim will be padded with additional 8 pixels\n",
      "new full images shape: \n",
      "(2, 1, 1888, 2816)\n",
      "Number of patches on h : 195\n",
      "Number of patches on w : 294\n",
      "number of patches per image: 57330, totally for this dataset: 114660\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-490d5993e357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtest_border_masks_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaint_border_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_border_masks_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatch_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtest_border_masks_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaint_border_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_border_masks_4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatch_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpatches_border_masks_test_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_ordered_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_border_masks_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mpatches_border_masks_test_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_ordered_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_border_masks_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mpatches_border_masks_test_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_ordered_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_border_masks_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/peng/KunChi/论文大修/sjk/extract_patches.py\u001b[0m in \u001b[0;36mextract_ordered_overlap\u001b[0;34m(full_imgs, patch_h, patch_w, stride_h, stride_w)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of patches on w : \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpatch_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mstride_w\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"number of patches per image: \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_patches_img\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\", totally for this dataset: \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_patches_tot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_patches_tot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatch_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatch_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0miter_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m   \u001b[0;31m#iter over the total number of patches (N_patches)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#loop over the full images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#test_imgs_orig = load_hdf5(original_imgs_test)\n",
    "#test_imgs_truth = load_hdf5(groundTruth_imgs_test)\n",
    "#test_border_masks = load_hdf5(borderMasks_imgs_test)\n",
    "\n",
    "test_border_masks_1 = load_hdf5(borderMasks_imgs_test_1)\n",
    "test_border_masks_2 = load_hdf5(borderMasks_imgs_test_3)\n",
    "test_border_masks_3 = load_hdf5(borderMasks_imgs_test_4)\n",
    "test_border_masks_4 = load_hdf5(borderMasks_imgs_test_5)\n",
    "test_border_masks_1 = test_border_masks_1/255.\n",
    "test_border_masks_2 = test_border_masks_2/255.\n",
    "test_border_masks_3 = test_border_masks_3/255.\n",
    "test_border_masks_4 = test_border_masks_4/255.\n",
    "test_border_masks_1 = test_border_masks_1[0:2, :, :, :]\n",
    "test_border_masks_2 = test_border_masks_2[0:3, :, :, :]\n",
    "test_border_masks_3 = test_border_masks_3[0:1, :, :, :]\n",
    "test_border_masks_4 = test_border_masks_4[0:2, :, :, :]\n",
    "test_border_masks_1 = paint_border_overlap(test_border_masks_1,patch_height, patch_width, stride_height, stride_width)\n",
    "test_border_masks_2 = paint_border_overlap(test_border_masks_2,patch_height, patch_width, stride_height, stride_width)\n",
    "test_border_masks_3 = paint_border_overlap(test_border_masks_3,patch_height, patch_width, stride_height, stride_width)\n",
    "test_border_masks_4 = paint_border_overlap(test_border_masks_4,patch_height, patch_width, stride_height, stride_width)\n",
    "patches_border_masks_test_1 = extract_ordered_overlap(test_border_masks_1, patch_height, patch_width, stride_height, stride_width)\n",
    "patches_border_masks_test_2 = extract_ordered_overlap(test_border_masks_2, patch_height, patch_width, stride_height, stride_width)\n",
    "patches_border_masks_test_3 = extract_ordered_overlap(test_border_masks_3, patch_height, patch_width, stride_height, stride_width)\n",
    "patches_border_masks_test_4 = extract_ordered_overlap(test_border_masks_4, patch_height, patch_width, stride_height, stride_width)\n",
    "test_border_masks = np.concatenate((patches_border_masks_test_1, patches_border_masks_test_2, patches_border_masks_test_3,\n",
    "                                    patches_border_masks_test_4),axis=0)\n",
    "\n",
    "def evaluate(model_name):\n",
    "     # get predictions\n",
    "    model.load_weights(model_name, by_name=True)\n",
    "    predictions = model.predict(te_data, verbose=2) #batch_size=1,\n",
    "    predictions = predictions[3]\n",
    "    \n",
    "    full_img_height = test_imgs_orig.shape[2]\n",
    "    full_img_width = test_imgs_orig.shape[3]\n",
    "    test_border_masks = test_border_masks\n",
    "    N_visual = 1\n",
    "    \n",
    "    # re-component to full size\n",
    "    predictions = np.transpose(predictions,(0,3,1,2))\n",
    "    predictions = recompone_overlap(predictions, new_height, new_width, stride_height, stride_width)# predictions\n",
    "    gtruth_masks = te_mask\n",
    "    \n",
    "    # back to original dimensions\n",
    "    predictions = predictions[:, :, 0:full_img_height, 0:full_img_width]\n",
    "    pred_imgs = predictions\n",
    "    orig_imgs = my_PreProc(test_imgs_orig[0:pred_imgs.shape[0], :, :, :])\n",
    "    shape = predictions.shape\n",
    "    \n",
    "    def dice_score(y_true, y_pred):\n",
    "        # y = K.round(K.flatten(y_pred))#tf.one_hot(pred_max,depth=num_classes)\n",
    "        # x = K.round(K.flatten(y_true))\n",
    "        y_pred = y_pred[:,:,0:full_img_height,0:full_img_width]\n",
    "        p = y_pred.flatten()#tf.one_hot(pred_max,depth=num_classes)\n",
    "        t = y_true.flatten()\n",
    "        p,t = np.round(p),np.round(t)\n",
    "        intersection = np.sum(p * t)\n",
    "        union = np.sum(p) + np.sum(t)- intersection\n",
    "        dice = (2*intersection+0.001) /  (union+intersection+0.001)\n",
    "        return np.mean(dice)\n",
    "    print('dice:', dice_score(gtruth_masks,pred_imgs))\n",
    "    # apply the DRIVE masks on the repdictions #set everything outside the FOV to zero!!\n",
    "    kill_border(pred_imgs, test_border_masks)  #DRIVE MASK  #only for visualization\n",
    "    print(\"Orig imgs shape: \" +str(orig_imgs.shape))\n",
    "    print(\"pred imgs shape: \" +str(pred_imgs.shape))\n",
    "    print(\"Gtruth imgs shape: \" +str(gtruth_masks.shape))\n",
    "    visualize(group_images(orig_imgs,N_visual), \"all_originals\")#.show()\n",
    "    visualize(group_images(pred_imgs,N_visual), \"all_predictions\")#.show()\n",
    "    visualize(group_images(gtruth_masks,N_visual), \"all_groundTruths\")#.show()\n",
    "    #visualize results comparing mask and prediction:\n",
    "    assert (orig_imgs.shape[0]==pred_imgs.shape[0] and orig_imgs.shape[0]==gtruth_masks.shape[0])\n",
    "    N_predicted = orig_imgs.shape[0]\n",
    "    group = N_visual\n",
    "    assert (N_predicted%group==0)\n",
    "    for i in range(int(N_predicted/group)):\n",
    "        orig_stripe = group_images(orig_imgs[i*group:(i*group)+group,:,:,:],group)\n",
    "        masks_stripe = group_images(gtruth_masks[i*group:(i*group)+group,:,:,:],group)\n",
    "        pred_stripe = group_images(pred_imgs[i*group:(i*group)+group,:,:,:],group)\n",
    "        total_img = np.concatenate((orig_stripe,masks_stripe,pred_stripe),axis=0)\n",
    "        visualize(total_img,\"Original_GroundTruth_Prediction\"+str(i))#.show()\n",
    "        \n",
    "    #====== Evaluate the results\n",
    "    print(\"\\n\\n========  Evaluate the results =======================\")\n",
    "    #predictions only inside the FOV\n",
    "    y_scores, y_true = pred_only_FOV(pred_imgs, gtruth_masks, test_border_masks)  #returns data only inside the FOV\n",
    "    #y_true = (np.round(y_true)).astype(np.int32)\n",
    "    print(\"Calculating results only inside the FOV:\")\n",
    "    print(\"y scores pixels: \" +str(y_scores.shape[0]) +\" (radius 270: 270*270*3.14==228906), including background around retina: \" +str(pred_imgs.shape[0]*pred_imgs.shape[2]*pred_imgs.shape[3]) +\" (584*565==329960)\")\n",
    "    print(\"y true pixels: \" +str(y_true.shape[0]) +\" (radius 270: 270*270*3.14==228906), including background around retina: \" +str(gtruth_masks.shape[2]*gtruth_masks.shape[3]*gtruth_masks.shape[0])+\" (584*565==329960)\")\n",
    "    \n",
    "    #Area under the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve((y_true), y_scores)\n",
    "    AUC_ROC = roc_auc_score(y_true, y_scores)\n",
    "    # test_integral = np.trapz(tpr,fpr) #trapz is numpy integration\n",
    "    print(\"\\nArea under the ROC curve: \" +str(AUC_ROC))\n",
    "    roc_curve_f =plt.figure()\n",
    "    plt.plot(fpr,tpr,'-',color='darkorange',lw=2,label='Area Under the Curve (AUC = %0.4f)' % AUC_ROC)\n",
    "    plt.plot([0,1],[0,1],color='navy',linestyle='--',lw=2)\n",
    "    plt.title('ROC curve')\n",
    "    plt.xlim([0.,1.])\n",
    "    plt.ylim([0.,1.005])\n",
    "#     plt.plot(fpr,tpr,'-',label='Area Under the Curve (AUC = %0.4f)' % AUC_ROC)\n",
    "#     plt.title('ROC curve')\n",
    "    plt.xlabel(\"FPR (False Positive Rate)\")\n",
    "    plt.ylabel(\"TPR (True Positive Rate)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"ROC.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    ############################################################################\n",
    "    #记录fpr、tpr\n",
    "    # save_path = './csv_results/' + model_name.split('/')[2].split('.')[0] + '_fpr_tpr.csv'\n",
    "    save_path = './csv_results/' + model_name.split('.')[0] + '_fpr_tpr.csv'\n",
    "    df = pd.DataFrame.from_dict({'fpr': fpr, 'tpr': tpr})\n",
    "    df.to_csv(save_path)\n",
    "    print('ROC曲线的.csv文件已保存到' + save_path)\n",
    "    ############################################################################\n",
    "        \n",
    "    #Precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "    precision = np.fliplr([precision])[0]  #so the array is increasing (you won't get negative AUC)\n",
    "    recall = np.fliplr([recall])[0]  #so the array is increasing (you won't get negative AUC)\n",
    "    AUC_prec_rec = np.trapz(precision,recall)\n",
    "    \n",
    "    ############################################################################\n",
    "    #记录recall、precision\n",
    "    # save_path = './csv_results/'+ model_name.split('/')[2].split('.')[0] +'_precision_recall.csv'\n",
    "    save_path = './csv_results/' + model_name.split('.')[0] + '_precision_recall.csv'\n",
    "    df = pd.DataFrame.from_dict({'precision': precision, 'recall': recall})\n",
    "    df.to_csv(save_path)\n",
    "    print('PR曲线的.csv文件已保存到' + save_path)\n",
    "    ############################################################################\n",
    "    \n",
    "    print(\"\\nArea under Precision-Recall curve: \" +str(AUC_prec_rec))\n",
    "    prec_rec_curve = plt.figure()\n",
    "    plt.plot(recall,precision,'-',lw=2,color='darkorange',label='Area Under the Curve (AUC = %0.4f)' % AUC_prec_rec)\n",
    "    plt.plot([1,0],[0,1],color='navy',linestyle='--',lw=2)\n",
    "    plt.xlim([0.,1.])\n",
    "    plt.ylim([0.,1.005])\n",
    "#     plt.plot(recall,precision,'-',label='Area Under the Curve (AUC = %0.4f)' % AUC_prec_rec)\n",
    "#     plt.title('Precision - Recall curve')\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"Precision_recall.png\")\n",
    "    plt.show()\n",
    "    #Confusion matrix\n",
    "    threshold_confusion = 0.5\n",
    "    print(\"\\nConfusion matrix:  Custom threshold (for positive) of \" +str(threshold_confusion))\n",
    "    y_pred = np.empty((y_scores.shape[0]))\n",
    "    for i in range(y_scores.shape[0]):\n",
    "        if y_scores[i]>=threshold_confusion:\n",
    "            y_pred[i]=1\n",
    "        else:\n",
    "            y_pred[i]=0\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    print(confusion)\n",
    "    accuracy = 0\n",
    "    if float(np.sum(confusion))!=0:\n",
    "        accuracy = float(confusion[0,0]+confusion[1,1])/float(np.sum(confusion))\n",
    "    print(\"Global Accuracy: \" +str(accuracy))\n",
    "    specificity = 0\n",
    "    if float(confusion[0,0]+confusion[0,1])!=0:\n",
    "        specificity = float(confusion[0,0])/float(confusion[0,0]+confusion[0,1])\n",
    "    print(\"Specificity: \" +str(specificity))\n",
    "    sensitivity = 0\n",
    "    if float(confusion[1,1]+confusion[1,0])!=0:\n",
    "        sensitivity = float(confusion[1,1])/float(confusion[1,1]+confusion[1,0])\n",
    "    print(\"Sensitivity: \" +str(sensitivity))\n",
    "    precision = 0\n",
    "    if float(confusion[1,1]+confusion[0,1])!=0:\n",
    "        precision = float(confusion[1,1])/float(confusion[1,1]+confusion[0,1])\n",
    "    print(\"Precision: \" +str(precision))\n",
    "\n",
    "    # #Jaccard Jaccard similarity coefficient score\n",
    "    # jaccard = jaccard_score(y_true, y_pred)\n",
    "    # print(\"\\nJaccard : \" +str(jaccard))\n",
    "\n",
    "    # jaccard_score(y_true, y_pred)\n",
    "    #Jaccard similarity index\n",
    "    jaccard_index = jaccard_similarity_score(y_true, y_pred, normalize=True)\n",
    "    print(\"\\nJaccard similarity score: \" +str(jaccard_index))\n",
    "\n",
    "    #F1 score\n",
    "    F1_score = f1_score(y_true, y_pred, labels=None, average='binary', sample_weight=None)\n",
    "    print(\"\\nF1 score (F-measure): \" +str(F1_score))\n",
    "\n",
    "    #Save the results\n",
    "#     file_perf = open('performances.txt', 'w')\n",
    "    # file_perf = open('./performance_results/'+ model_name.split('/')[2].split('.')[0] +'_performances.txt', 'w')\n",
    "    file_perf = open('./performance_results/' + model_name.split('.')[0] + '_performances.txt', 'w')\n",
    "    file_perf.write(\"Area under the ROC curve: \"+str(AUC_ROC)\n",
    "                    + \"\\nArea under Precision-Recall curve: \" +str(AUC_prec_rec)\n",
    "                    + \"\\nJaccard similarity score: \" +str(jaccard_index)\n",
    "                    + \"\\nF1 score (F-measure): \" +str(F1_score)\n",
    "                    +\"\\n\\nConfusion matrix:\"\n",
    "                    +str(confusion)\n",
    "                    +\"\\nACCURACY: \" +str(accuracy)\n",
    "                    +\"\\nSENSITIVITY: \" +str(sensitivity)\n",
    "                    +\"\\nSPECIFICITY: \" +str(specificity)\n",
    "                    +\"\\nPRECISION: \" +str(precision)\n",
    "                    )\n",
    "    file_perf.close()\n",
    "    # print(model_name.split('/')[2].split('.')[0]+'的性能文件已保存到'+'./performance_results/'+ model_name.split('/')[2].split('.')[0] +'_performances.txt')\n",
    "    print(model_name.split('.')[0]+'的性能文件已保存到'+'./performance_results/'+ model_name.split('.')[0] +'_performances.txt')\n",
    "    \n",
    "def show_result(items=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]): #0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19\n",
    "    dice_out = 0\n",
    "    print(\"=\"*50)\n",
    "    print(\"红色是预测结果缺少的，蓝色是多出来的\")\n",
    "    print(\"=\"*50)\n",
    "    for i in items:#range(20):\n",
    "        img = plt.imread('Original_GroundTruth_Prediction{}.png'.format(i))\n",
    "        #img_ori = img[:960,:]\n",
    "#         test_imgs_orig = load_hdf5(original_imgs_test)\n",
    "        # print(test_imgs_orig)\n",
    "        img_ori = np.transpose(test_imgs_orig[i,:,:,:],(1,2,0))/255.\n",
    "        img = np.round(img)\n",
    "        img_mask = img[584:1168,:]\n",
    "        img = img[1168:,:]\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.subplot(221)\n",
    "        plt.imshow(img_mask,'gray')\n",
    "        # plt.subplot(222)\n",
    "        # plt.imshow(img,'gray')\n",
    "        # plt.show()\n",
    "        # print(img.shape,img.shape[0]/3.*2)\n",
    "        # img = cv2.erode(img,np.ones((2,2)))\n",
    "        # img = cv2.dilate(img,np.ones((2,2)))\n",
    "        # https://blog.csdn.net/qq_30490125/article/details/80490776 开闭操作  cv2.MORPH_OPEN  cv2.MORPH_CLOSE\n",
    "        # retval=cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "        # # 核的形状，有cv2.MORPH_RECT , cv2.MORPH_CROSS和cv2.MORPH_ELLIPSE \n",
    "        # img = cv2.morphologyEx(img,cv2.MORPH_CLOSE,retval)\n",
    "        # img = cv2.morphologyEx(img,cv2.MORPH_OPEN,retval)\n",
    "        plt.subplot(222)\n",
    "        plt.imshow(img_ori)\n",
    "        plt.subplot(223)\n",
    "        plt.imshow(img, 'gray')\n",
    "        plt.subplot(224)\n",
    "        #img_result = img_ori\n",
    "        #img_result = img\n",
    "        img_result = np.stack([img]*3,axis=-1)\n",
    "        #img_result = np.stack([img_ori]*3,axis=-1)\n",
    "        img_result[:,:,0]=np.where(img<img_mask,1.,img_result[:,:,0])        \n",
    "        img_result[:,:,1]=np.where(img<img_mask,0.,img_result[:,:,1])\n",
    "        img_result[:,:,2]=np.where(img<img_mask,0.,img_result[:,:,2])\n",
    "        #############红色是预测结果缺少的，蓝色是多出来的\n",
    "        img_result[:,:,0]=np.where(img>img_mask,0.,img_result[:,:,0])\n",
    "        img_result[:,:,1]=np.where(img>img_mask,0.,img_result[:,:,1])\n",
    "        img_result[:,:,2]=np.where(img>img_mask,1.,img_result[:,:,2])\n",
    "        \n",
    "        plt.imshow(img_result)\n",
    "        plt.tight_layout()\n",
    "        iou = (np.sum(np.where(img + img_mask == 2, 1, 0))) / (np.sum((np.where(img + img_mask, 1, 0))))\n",
    "        # dice = (2*jaccard)/(1+jaccard)   jaccard=dice/(2-dice)\n",
    "        print(i, iou, 2 * iou / (1 + iou))\n",
    "        dice_out += (2 * iou / (1 + iou)) #2,5,7,17,6,8,9,10,14,15\n",
    "        plt.title('Dice:{}'.format(2 * iou / (1 + iou)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-period",
   "metadata": {},
   "source": [
    "# Defining blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-flood",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:15:17.748827Z",
     "start_time": "2024-03-09T13:14:19.218Z"
    }
   },
   "outputs": [],
   "source": [
    "init = tf.keras.initializers.glorot_uniform(seed=1)\n",
    "\n",
    "def convolution_block(x, filters, size):\n",
    "    outputs = Conv2D(kernel_size=size, filters=filters, strides=1, padding='same', use_bias=False, kernel_initializer=init)(x)\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=size, filters=filters, strides=1, padding='same', use_bias=False, kernel_initializer=init)(outputs)\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    return outputs\n",
    "\n",
    "#---------------------------------------------------------------------------cbam模块---------------------------------------------------------------------------\n",
    "channel_axis = 1 if K.image_data_format() == \"channels_first\" else 3\n",
    "def channel_attention(input_xs, reduction_ratio=0.125):\n",
    "    # get channel\n",
    "    channel = int(input_xs.shape[channel_axis])\n",
    "    maxpool_channel = KL.GlobalMaxPooling2D()(input_xs)\n",
    "    maxpool_channel = KL.Reshape((1, 1, channel))(maxpool_channel)\n",
    "    avgpool_channel = KL.GlobalAvgPool2D()(input_xs)\n",
    "    avgpool_channel = KL.Reshape((1, 1, channel))(avgpool_channel)\n",
    "    Dense_One = KL.Dense(units=int(channel * reduction_ratio), activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n",
    "    Dense_Two = KL.Dense(units=int(channel), activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n",
    "    # max path\n",
    "    mlp_1_max = Dense_One(maxpool_channel)\n",
    "    mlp_2_max = Dense_Two(mlp_1_max)\n",
    "    mlp_2_max = KL.Reshape(target_shape=(1, 1, int(channel)))(mlp_2_max)\n",
    "    # avg path\n",
    "    mlp_1_avg = Dense_One(avgpool_channel)\n",
    "    mlp_2_avg = Dense_Two(mlp_1_avg)\n",
    "    mlp_2_avg = KL.Reshape(target_shape=(1, 1, int(channel)))(mlp_2_avg)\n",
    "    channel_attention_feature = KL.Add()([mlp_2_max, mlp_2_avg])\n",
    "    channel_attention_feature = KL.Activation('sigmoid')(channel_attention_feature)\n",
    "    return KL.Multiply()([channel_attention_feature, input_xs])\n",
    "\n",
    "def spatial_attention(channel_refined_feature):\n",
    "    maxpool_spatial = KL.Lambda(lambda x: K.max(x, axis=3, keepdims=True))(channel_refined_feature)\n",
    "    avgpool_spatial = KL.Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(channel_refined_feature)\n",
    "    max_avg_pool_spatial = KL.Concatenate(axis=3)([maxpool_spatial, avgpool_spatial])\n",
    "    return KL.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(max_avg_pool_spatial)\n",
    "\n",
    "def cbam_block(inputs, reduction_ratio=0.5):\n",
    "    channel_refined_feature = channel_attention(inputs, reduction_ratio=reduction_ratio)\n",
    "    outputs = KL.Multiply()([channel_refined_feature, inputs])\n",
    "    spatial_attention_feature = spatial_attention(outputs)\n",
    "    outputs = KL.Multiply()([spatial_attention_feature, inputs])\n",
    "    return outputs\n",
    "#---------------------------------------------------------------------------cbam模块----------------------------------------------------------------------------\n",
    "\n",
    "#------------------------------------------------aff模块------------------------------------------------\n",
    "def se_net(x, r=4):\n",
    "    input_channel = x.shape[-1]\n",
    "    outputs = KL.GlobalMaxPooling2D()(x)\n",
    "    outputs = KL.Reshape((1, 1, input_channel))(outputs)\n",
    "    outputs = Dense(input_channel // r)(outputs)\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    outputs = Dense(input_channel)(outputs)\n",
    "    outputs = Activation('sigmoid')(outputs)\n",
    "    outputs = KL.Multiply()([x, outputs])\n",
    "    return outputs\n",
    "\n",
    "def aff_block(low_x, high_x):\n",
    "    outputs = concatenate([high_x, low_x], axis=3)\n",
    "    outputs = se_net(outputs)\n",
    "    outputs = Conv2D(kernel_size=(1, 1), filters=int(outputs.shape[-1] / 2), strides=1, padding='same')(outputs)\n",
    "    outputs = KL.GlobalMaxPooling2D()(outputs)\n",
    "    outputs = KL.Reshape((1, 1, outputs.shape[-1]))(outputs)\n",
    "    outputs = Activation('sigmoid')(outputs)\n",
    "    outputs = KL.Multiply()([low_x, outputs])\n",
    "    outputs = KL.add([outputs, high_x])\n",
    "    return outputs\n",
    "#------------------------------------------------aff模块------------------------------------------------\n",
    "\n",
    "\n",
    "#------------------------------------------------ASPP模块------------------------------------------------\n",
    "def aspp_block(input_layer, filters, rates):\n",
    "    conv3x3_0 = Conv2D(filters, (3, 3), activation='relu', padding='same', dilation_rate=rates[0])(input_layer)\n",
    "    conv3x3_1 = Conv2D(filters, (3, 3), activation='relu', padding='same', dilation_rate=rates[1])(input_layer)\n",
    "    conv3x3_2 = Conv2D(filters, (3, 3), activation='relu', padding='same', dilation_rate=rates[2])(input_layer)\n",
    "    conv3x3_3 = Conv2D(filters, (3, 3), activation='relu', padding='same', dilation_rate=rates[3])(input_layer)\n",
    "    # 平均池化层\n",
    "    pool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(input_layer)\n",
    "    pool_conv = Conv2D(filters, (1, 1), activation='relu', padding='same')(pool)\n",
    "    # 将所有的特征图连接起来\n",
    "    concatenated = Concatenate()([conv3x3_0, conv3x3_1, conv3x3_2, conv3x3_3, pool_conv])\n",
    "    conv1x1 = Conv2D(filters, (1, 1), activation='relu', padding='same')(concatenated)\n",
    "    return conv1x1\n",
    "#------------------------------------------------ASPP模块------------------------------------------------\n",
    "\n",
    "def res_block(x, filters, size):\n",
    "    x = Conv2D(kernel_size=size, filters=filters, strides=1, padding='same', use_bias=False, kernel_initializer=init, activation='relu')(x)\n",
    "    outputs = Conv2D(kernel_size=size, filters=filters, strides=1, padding='same', use_bias=False, kernel_initializer=init)(x)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Dropout(0.5)(outputs)\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=size, filters=filters, strides=1, padding='same', use_bias=False, kernel_initializer=init)(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = KL.add([outputs, x])\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    return outputs\n",
    "\n",
    "def res_path(x, filters, size):\n",
    "    outputs = Conv2D(kernel_size=size, filters=filters, strides=1, dilation_rate=(2, 2), padding='same', use_bias=False, kernel_initializer=init)(x)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    x = Conv2D(kernel_size=(1, 1), filters=filters, strides=1, padding='same')(x)\n",
    "    outputs = KL.add([outputs, x])\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    return outputs\n",
    "\n",
    "def outputs_layer(x, filters, size):\n",
    "    outputs = Conv2D(kernel_size=size, filters=filters, strides=1, padding='same', use_bias=False, kernel_initializer=init)(x)\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=size, filters=filters, strides=1, padding='same', use_bias=False, kernel_initializer=init)(outputs)\n",
    "    outputs = Activation('sigmoid')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    return outputs\n",
    "\n",
    "def atrous_block(x, filters):\n",
    "    outputs_1 = Conv2D(kernel_size=(3, 3), filters=filters, strides=1, dilation_rate=(1, 1), padding='same')(x)\n",
    "    outputs_2 = Conv2D(kernel_size=(3, 3), filters=filters, strides=1, dilation_rate=(3, 3), padding='same')(x)\n",
    "    outputs_2 = Conv2D(kernel_size=(3, 3), filters=filters, strides=1, dilation_rate=(1, 1), padding='same')(outputs_2)\n",
    "    outputs_3 = Conv2D(kernel_size=(3, 3), filters=filters, strides=1, dilation_rate=(1, 1), padding='same')(x)\n",
    "    outputs_3 = Conv2D(kernel_size=(3, 3), filters=filters, strides=1, dilation_rate=(3, 3), padding='same')(outputs_3)\n",
    "    outputs_3 = Conv2D(kernel_size=(3, 3), filters=filters, strides=1, dilation_rate=(1, 1), padding='same')(outputs_3)\n",
    "    outputs = outputs_1 + outputs_2 + outputs_3\n",
    "    return outputs\n",
    "\n",
    "def attention_gate_block(x_l, x_g):\n",
    "    outputs = Conv2D(kernel_size=(1, 1), filters=x_l.shape[-1], strides=2, padding='same')(x_l)\n",
    "    outputs = Conv2D(kernel_size=(3, 3), filters=x_l.shape[-1], strides=1, padding='same')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    x_g = Conv2D(kernel_size=(3, 3), filters=x_g.shape[-1], strides=1, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    outputs = x_g + outputs\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=(3, 3), filters=x_g.shape[-1], strides=1, padding='same')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    psi = Activation('sigmoid')(outputs)\n",
    "    psi = UpSampling2D()(outputs)\n",
    "    outputs = x_l * psi\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-minnesota",
   "metadata": {},
   "source": [
    "# Modified Unet module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-newark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:15:17.749782Z",
     "start_time": "2024-03-09T13:14:19.229Z"
    }
   },
   "outputs": [],
   "source": [
    "def Unet_modified_3(img_rows, img_cols, channels=1, num_class=1, DropoutRatio=0):\n",
    "    num_f = [32,64,128,256,512,1024]\n",
    "    inputs = Input((img_rows, img_cols, channels))\n",
    "    \n",
    "    #encoder\n",
    "    conv1_0 = res_block(inputs, num_f[0], (3, 3))\n",
    "    \n",
    "    maxpooling = MaxPooling2D()(conv1_0)\n",
    "    \n",
    "    conv2_0 = res_block(maxpooling, num_f[1], (3, 3))\n",
    "    \n",
    "    maxpooling = MaxPooling2D()(conv2_0)\n",
    "    \n",
    "    conv3_0 = res_block(maxpooling, num_f[2], (3, 3))\n",
    "    \n",
    "    maxpooling = MaxPooling2D()(conv3_0)\n",
    "    \n",
    "    conv4_0 = res_block(maxpooling, num_f[3], (3, 3))\n",
    "    \n",
    "    maxpooling = MaxPooling2D()(conv4_0)\n",
    "    \n",
    "    conv5_0 = res_block(maxpooling, num_f[4], (3, 3))\n",
    "    \n",
    "    #decoder\n",
    "    conv4_1 = res_path(conv4_0, num_f[4], (3, 3))\n",
    "    fusion = aff_block(conv4_1, UpSampling2D()(conv5_0))\n",
    "    conv4_2 = res_block(fusion, num_f[3], (3, 3))\n",
    "    \n",
    "    conv3_1 = res_path(conv3_0, num_f[3], (3, 3))\n",
    "    fusion = aff_block(conv3_1, UpSampling2D()(conv4_2))\n",
    "    conv3_2 = res_block(fusion, num_f[2], (3, 3))\n",
    "    \n",
    "    conv2_1 = res_path(conv2_0, num_f[2], (3, 3))\n",
    "    fusion = aff_block(conv2_1, UpSampling2D()(conv3_2))\n",
    "    conv2_2 = res_block(fusion, num_f[1], (3, 3))\n",
    "    \n",
    "    conv1_1 = res_path(conv1_0, num_f[1], (3, 3))\n",
    "    fusion = aff_block(conv1_1, UpSampling2D()(conv2_2))\n",
    "    conv1_2 = res_block(fusion, num_f[0], (3, 3))\n",
    "    \n",
    "    #decoder        (AR Path----->ASPP)\n",
    "    #conv4_1 = aspp_block(conv4_0, num_f[4], [6,12,18,24])\n",
    "    #fusion = aff_block(conv4_1, UpSampling2D()(conv5_0))\n",
    "    #conv4_2 = res_block(fusion, num_f[3], (3, 3))\n",
    "    #\n",
    "    #conv3_1 = aspp_block(conv3_0, num_f[3], [6,12,18,24])\n",
    "    #fusion = aff_block(conv3_1, UpSampling2D()(conv4_2))\n",
    "    #conv3_2 = res_block(fusion, num_f[2], (3, 3))\n",
    "    #\n",
    "    #conv2_1 = aspp_block(conv2_0, num_f[2], [6,12,18,24])\n",
    "    #fusion = aff_block(conv2_1, UpSampling2D()(conv3_2))\n",
    "    #conv2_2 = res_block(fusion, num_f[1], (3, 3))\n",
    "    #\n",
    "    #conv1_1 = aspp_block(conv1_0, num_f[1],[6,12,18,24])\n",
    "    #fusion = aff_block(conv1_1, UpSampling2D()(conv2_2))\n",
    "    #conv1_2 = res_block(fusion, num_f[0], (3, 3))\n",
    "    \n",
    "    sup_3 = UpSampling2D()(conv4_2)\n",
    "    sup_3 = UpSampling2D()(sup_3)\n",
    "    sup_3 = UpSampling2D()(sup_3)\n",
    "    sup_3 = Conv2D(kernel_size=(1, 1), filters=num_class, strides=1, padding='same', activation='sigmoid')(sup_3)\n",
    "    \n",
    "    sup_2 = UpSampling2D()(conv3_2)\n",
    "    sup_2 = UpSampling2D()(sup_2)\n",
    "    sup_2 = Conv2D(kernel_size=(1, 1), filters=num_class, strides=1, padding='same', activation='sigmoid')(sup_2)\n",
    "    \n",
    "    sup_1 = UpSampling2D()(conv2_2)\n",
    "    sup_1 = Conv2D(kernel_size=(1, 1), filters=num_class, strides=1, padding='same', activation='sigmoid')(sup_1)\n",
    "    \n",
    "    outputs = Conv2D(kernel_size=(1, 1), filters=num_class, strides=1, padding='same', activation='sigmoid')(conv1_2)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[sup_3, sup_2, sup_1, outputs])  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-trading",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-sending",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:15:17.750615Z",
     "start_time": "2024-03-09T13:14:19.240Z"
    }
   },
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def __init__(self,model, model_name, **kwargs):\n",
    "    # self.output_dim = output_dim\n",
    "        super(LossHistory, self).__init__(**kwargs)\n",
    "        self.model = model\n",
    "        self.model_name = model_name\n",
    "        self.best_val_dice=0\n",
    "        self.record_dict = []\n",
    "        self.loss,self.pr,self.re,self.F,self.dice,self.acc= [],[],[],[],[],[]\n",
    "        with open(self.model_name[:-3]+'.json', 'w') as fp:  #清空文件\n",
    "            fp.write('')\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        epoch_metric = dict()\n",
    "        for meric_name in ['loss','pr','re','F','dice','acc']:\n",
    "            epoch_metric[meric_name] = float(logs.get(meric_name)) #转换为python的浮点\n",
    "            epoch_metric['val_'+meric_name] = float(logs.get('val_'+meric_name)) #转换为python的浮点\n",
    "        #字典json自动排序F, acc, dice, loss, pr, re\n",
    "        with open(self.model_name[:-3]+'.json', 'a') as fp:\n",
    "            json.dump({epoch:epoch_metric}, fp, indent=4, sort_keys=True)\n",
    "        val_dice = logs.get('val_dice')\n",
    "        if val_dice>self.best_val_dice:\n",
    "            self.best_val_dice = val_dice\n",
    "            print('\\nupdate best_val_dice:',self.best_val_dice)\n",
    "            self.model.save_weights(self.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-authorization",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:15:17.751366Z",
     "start_time": "2024-03-09T13:14:19.241Z"
    }
   },
   "outputs": [],
   "source": [
    "def re(y_true, y_pred):\n",
    "    p = K.round(K.flatten(y_pred))#K.flatten(y_pred)\n",
    "    t = K.flatten(y_true)\n",
    "    t_mask = tf.equal(t,1.0)\n",
    "    p_mask = tf.boolean_mask(p,t_mask,name='t_mask')\n",
    "    re = K.sum(p_mask)/(K.sum(t)+10e-6)\n",
    "    return K.mean(re)\n",
    "  # return tf.keras.metrics.precision(y_true, y_pred)\n",
    "def pr(y_true, y_pred):\n",
    "    p = K.round(K.flatten(y_pred))#K.flatten(1.-y_pred)\n",
    "    t = K.flatten(y_true)\n",
    "    t_mask = tf.equal(t,1.)\n",
    "    p_mask = tf.boolean_mask(p,t_mask,name='t_mask')\n",
    "    pr = K.sum(p_mask)/(K.sum(p)+10e-6)\n",
    "    return K.mean(pr)\n",
    "  # return tf.keras.metrics.recall(y_true, y_pred)\n",
    "def F(y_true, y_pred):\n",
    "    return 2./(1./pr(y_true,y_pred)+1./re(y_true,y_pred))\n",
    "def m(y_true, y_pred):\n",
    "    return tf.keras.metrics.mean_iou(y_true,y_pred,num_classes=1)\n",
    "def dice(y_true, y_pred):\n",
    "    p = K.flatten(y_pred)#tf.one_hot(pred_max,depth=num_classes)\n",
    "    t = K.flatten(y_true)\n",
    "    p,t = K.round(p),K.round(t)\n",
    "    intersection = K.sum(p * t)\n",
    "    union = K.sum(p) + K.sum(t)- intersection\n",
    "    dice = (2*intersection+0.001) /  (union+intersection+0.001)\n",
    "    return K.mean(dice)\n",
    "def LSL(y_true, y_pred):\n",
    "    y_pred_bc = y_pred\n",
    "    y_pred = 2. * y_pred - 1.\n",
    "    y_true_bc  = y_true \n",
    "    return 0.9*lovasz_hinge(logits=y_pred,labels=y_true,ignore=None,per_image=True) +  0.1*binary_crossentropy(y_true_bc,y_pred_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-demonstration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:15:17.752151Z",
     "start_time": "2024-03-09T13:14:19.242Z"
    }
   },
   "outputs": [],
   "source": [
    "my_loss = [dice_loss, dice_loss, dice_loss, dice_loss]\n",
    "my_weights = [1, 1, 4, 10]\n",
    "def train(model, model_name, losshistory, loss=my_loss, loss_weights=my_weights):\n",
    "    start = time.time()\n",
    "    print(time.strftime('%H:%M:%S', time.localtime((time.time()))))\n",
    "    earlystop_callback = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=20)\n",
    "    for i in range(1):\n",
    "        d = np.math.pow(10, i)\n",
    "        sgd = optimizers.SGD(lr=0.01/d, decay=1e-3/d, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss=loss, loss_weights=loss_weights, optimizer=sgd, metrics=[pr,re,F,dice,'acc'])\n",
    "        if(i != 0): model.load_weights(model_name)\n",
    "        #model.fit(tr_data, tr_mask, epochs=int(15 / (i + 1)), batch_size=8, verbose=1, shuffle=True,\n",
    "        #          validation_split=0.3, callbacks=[losshistory, earlystop_callback])\n",
    "        model.fit(tr_data, tr_mask, epochs=15, batch_size=8, verbose=1, shuffle=True)\n",
    "    time_cost = time.time() - start\n",
    "    print('time cost: {:.0f}h {:.0f}m {:.0f}s'.format(time_cost // 3600, (time_cost % 3600) // 60, time_cost % 60))\n",
    "    #model.load_weights(model_name)\n",
    "    model.save_weights(model_name)\n",
    "    #model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-celebrity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:15:17.752949Z",
     "start_time": "2024-03-09T13:14:19.244Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_shape = tr_data.shape\n",
    "model = Unet_modified_3(img_rows=data_shape[1], img_cols=data_shape[2], channels=data_shape[3])\n",
    "model_name = 'DRIVE307_1.h5'\n",
    "losshistory = LossHistory(model, model_name=model_name)\n",
    "train(model, model_name, losshistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-trail",
   "metadata": {},
   "source": [
    "# Results showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-protocol",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T13:15:17.753663Z",
     "start_time": "2024-03-09T13:14:19.255Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_shape = tr_data.shape\n",
    "model = Unet_modified_3(img_rows=data_shape[1], img_cols=data_shape[2], channels=data_shape[3], num_class=1)\n",
    "model_name = 'DRIVE307_1.h5'\n",
    "model.load_weights(model_name)\n",
    "evaluate(model_name=model_name)\n",
    "show_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-induction",
   "metadata": {},
   "source": [
    "# Last line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-intake",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
